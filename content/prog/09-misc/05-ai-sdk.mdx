import { Callout } from 'nextra/components'

# AI SDK

Unter https://sdk.vercel.ai ist ein AI SDK verfügbar, das für die Nutzung 
verschiedener LLMs eine einheitliche API bereitstellt und Funktionalitäten 
wie z.B. das Text-Streaming unterstützt. Mit Text-Streaming kann der Text einer 
Antwort der KI wie in den bekannten Chats als schrittweise erscheinender Text 
ausgegeben werden.

Folgender Beispiel-Code zeigt den Einsatz des AI SDKs mit dem OpenAI
und der Ausgabe der Antwort in einem Stream. Der Code implementiert einen
Chat mit fortlaufendem Kontext (`messages`), wobei hier der Einfachheit
halber kein System-Prompt zur Einschränkung auf die Ortssuche enthalten ist.

```js
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';
import { question } from 'readline-sync';

export default async function aiSearch() {
  console.clear();

  const messages = [];
  while (true) {
    let input = question(
      "Beschreibe den Ort (oder 'x' zum Beenden des Chats): "
    );
    if (input === 'x') return;

    messages.push({ role: 'user', content: input });

    const result = streamText({
      model: openai('gpt-4o'),
      messages,
    });

    let fullResponse = '';
    process.stdout.write('\nKI-Assistent: ');
    for await (const delta of result.textStream) {
      fullResponse += delta;
      process.stdout.write(delta);
    }
    process.stdout.write('\n\n');

    messages.push({ role: 'assistant', content: fullResponse });
  }
}
```

Damit der Code funktioniert, muss der API-Key in `.env` definiert sein,
siehe dazu die [vorige Lektion zu OpenAI](/prog/09-misc/01-openai).
Außerdem muss das AI-SDK installiert werden:

```bash
npm install ai @ai-sdk/openai
```

Für jeden Anbieter einer KI-API gibt es ggf. ein eigenes Package.
Wir verwenden `@ai-sdk/openai` für OpenAI.